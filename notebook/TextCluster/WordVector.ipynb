{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇：索引 {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "句子的向量：\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "bom_vectorizer = CountVectorizer()\n",
    "\n",
    "bom_X = bom_vectorizer.fit_transform(corpus)\n",
    "print(\"词汇：索引\", bom_vectorizer.vocabulary_)\n",
    "print(\"句子的向量：\")\n",
    "print(bom_X.toarray())#元素为每个词出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "[[0.   0.47 0.58 0.38 0.   0.   0.38 0.   0.38]\n",
      " [0.   0.69 0.   0.28 0.   0.54 0.28 0.   0.28]\n",
      " [0.51 0.   0.   0.27 0.51 0.   0.27 0.51 0.27]\n",
      " [0.   0.47 0.58 0.38 0.   0.   0.38 0.   0.38]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "#设置小数点的位数为2\n",
    "np.set_printoptions(2)\n",
    "tfidf_X = tfidf_vectorizer.fit_transform(corpus)\n",
    "#词汇表\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(tfidf_X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['are', 1], ['hello', 1], ['how', 1], ['you', 1]]\n",
      "[['how', 1], ['you', 1], ['do', 2]]\n",
      "[['are', 2], ['you', 3], ['doing', 2], ['hey', 1], ['what', 2], ['yes', 1]]\n",
      "[['are', 0.40251125658964493], ['hello', 0.8050225131792899], ['how', 0.40251125658964493], ['you', 0.16705726536655124]]\n",
      "[['how', 0.2413161129998105], ['you', 0.10015523607513224], ['do', 0.965264451999242]]\n",
      "[['are', 0.29633595631969156], ['you', 0.1844858013859942], ['doing', 0.5926719126393831], ['hey', 0.29633595631969156], ['what', 0.5926719126393831], ['yes', 0.29633595631969156]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "doc_list = [\n",
    "   \"Hello, how are you?\", \n",
    "   \"How do you do?\", \n",
    "   \"Hey what are you doing? yes you What are you doing?\"\n",
    "]\n",
    "doc_tokenized = [simple_preprocess(doc) for doc in doc_list]\n",
    "dictionary = corpora.Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_tokenized]\n",
    "for doc in BoW_corpus:\n",
    "   print([[dictionary[id], freq] for id, freq in doc])\n",
    "import numpy as np\n",
    "tfidf = models.TfidfModel(BoW_corpus, smartirs='ntc')\n",
    "for doc in tfidf[BoW_corpus]:\n",
    "   print([[dictionary[id], freq] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cc949ea91683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcorpus2dense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus2csc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mcorpus_tfidf_dense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus2dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mcorpus_tfidf_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus2csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36mcorpus2csc\u001b[1;34m(corpus, num_terms, dtype, num_docs, num_nnz, printprogress)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mnum_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;31m# now num_docs, num_terms and num_nnz contain the correct values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "doc_list = [\n",
    "   \"Hello, how are you?\", \n",
    "   \"How do you do?\", \n",
    "   \"Hey what are you doing? yes you What are you doing?\"\n",
    "]\n",
    "doc_tokenized = [simple_preprocess(doc) for doc in doc_list]\n",
    "\n",
    "dictionary = Dictionary(doc_tokenized)\n",
    "num_docs = dictionary.num_docs\n",
    "num_terms = len(dictionary.keys())\n",
    "corpus_bow = [dictionary.doc2bow(doc) for doc in doc_tokenized]\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]\n",
    "from gensim.matutils import corpus2dense, corpus2csc\n",
    "corpus_tfidf_dense = corpus2dense(corpus_tfidf, num_terms, num_docs)\n",
    "corpus_tfidf_sparse = corpus2csc(corpus_tfidf, num_terms, num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3271846 , 0.        , 0.22731014],\n",
       "       [0.8865103 , 0.        , 0.        ],\n",
       "       [0.3271846 , 0.18147115, 0.        ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9833963 , 0.        ],\n",
       "       [0.        , 0.        , 0.6158994 ],\n",
       "       [0.        , 0.        , 0.3079497 ],\n",
       "       [0.        , 0.        , 0.6158994 ],\n",
       "       [0.        , 0.        , 0.3079497 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf_dense"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondafb7c31c4956d4471a0bbe6c2dd07aa3f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
